"""
FIX-064 Phase 3: Option Tick Aggregation Test

Tests the Python-based aggregation logic that replaces the PostgreSQL trigger
`trg_option_tick_to_candle`. Uses the iceberg_test schema to avoid affecting
production data.

Usage:
    python test_option_tick_aggregation.py

Requirements:
    pip install asyncpg structlog
"""
import asyncio
import os
from datetime import datetime, timedelta
from decimal import Decimal
from typing import Any, Dict, List, Optional

import asyncpg
import structlog

logger = structlog.get_logger(__name__)

# Database connection
DB_CONFIG = {
    "host": "34.180.57.7",
    "port": 5432,
    "user": "iceberg",
    "password": "xw8vntEkMkLnOrwA6qsULpGmB1wUmgpT",
    "database": "iceberg",
}

# Test schema
TEST_SCHEMA = "iceberg_test"


async def setup_test_schema(conn: asyncpg.Connection) -> None:
    """Create test schema and tables if they don't exist."""
    await conn.execute(f"""
        CREATE SCHEMA IF NOT EXISTS {TEST_SCHEMA};
        
        -- Ticks table (simulates ingestion.option_chain_ticks)
        CREATE TABLE IF NOT EXISTS {TEST_SCHEMA}.option_chain_ticks (
            id BIGSERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            expiry DATE NOT NULL,
            strike NUMERIC(12,2) NOT NULL,
            option_type VARCHAR(2) NOT NULL CHECK (option_type IN ('CE', 'PE')),
            ts TIMESTAMPTZ NOT NULL DEFAULT NOW(),
            ltp NUMERIC(12,2),
            oi BIGINT,
            volume BIGINT,
            created_at TIMESTAMPTZ DEFAULT NOW()
        );
        
        -- Candles table (simulates processing.option_chain_candles_5m)
        CREATE TABLE IF NOT EXISTS {TEST_SCHEMA}.option_chain_candles_5m (
            symbol VARCHAR(20) NOT NULL,
            expiry DATE NOT NULL,
            strike NUMERIC(12,2) NOT NULL,
            option_type VARCHAR(2) NOT NULL CHECK (option_type IN ('CE', 'PE')),
            bucket_ts TIMESTAMPTZ NOT NULL,
            trade_date DATE NOT NULL,
            open NUMERIC(12,2),
            high NUMERIC(12,2),
            low NUMERIC(12,2),
            close NUMERIC(12,2),
            oi_open BIGINT,
            oi_high BIGINT,
            oi_low BIGINT,
            oi_close BIGINT,
            vol_open BIGINT,
            vol_high BIGINT,
            vol_low BIGINT,
            vol_close BIGINT,
            tick_count INTEGER DEFAULT 0,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW(),
            PRIMARY KEY (symbol, expiry, strike, option_type, bucket_ts)
        );
        
        -- Indexes
        CREATE INDEX IF NOT EXISTS idx_test_ticks_ts 
            ON {TEST_SCHEMA}.option_chain_ticks(ts);
        CREATE INDEX IF NOT EXISTS idx_test_ticks_symbol_ts 
            ON {TEST_SCHEMA}.option_chain_ticks(symbol, ts);
    """)
    logger.info("test_schema_setup_complete", schema=TEST_SCHEMA)


async def cleanup_test_data(conn: asyncpg.Connection) -> None:
    """Clean up test data from previous runs."""
    await conn.execute(f"TRUNCATE {TEST_SCHEMA}.option_chain_ticks CASCADE;")
    await conn.execute(f"TRUNCATE {TEST_SCHEMA}.option_chain_candles_5m CASCADE;")
    logger.info("test_data_cleaned")


async def insert_test_ticks(
    conn: asyncpg.Connection,
    ticks: List[Dict[str, Any]],
) -> int:
    """Insert test ticks into the test schema."""
    count = 0
    for tick in ticks:
        # Use database NOW() with offset for consistent timestamps
        offset_seconds = tick.get("offset_seconds", 0)
        await conn.execute(f"""
            INSERT INTO {TEST_SCHEMA}.option_chain_ticks 
                (symbol, expiry, strike, option_type, ts, ltp, oi, volume)
            VALUES ($1, $2, $3, $4, NOW() - INTERVAL '{offset_seconds} seconds', $5, $6, $7)
        """, tick["symbol"], tick["expiry"], tick["strike"], tick["option_type"],
            tick["ltp"], tick["oi"], tick["volume"])
        count += 1
    logger.info("test_ticks_inserted", count=count)
    return count


async def aggregate_option_ticks_to_candles(
    conn: asyncpg.Connection,
    lookback_seconds: int = 10,
) -> int:
    """
    Aggregate recent option ticks to 5-minute candles.
    
    This is the same logic as in indicator_scheduler.py but using the test schema.
    
    Args:
        conn: Database connection
        lookback_seconds: How far back to look for ticks
        
    Returns:
        Number of candles upserted
    """
    query = f"""
        WITH recent_ticks AS (
            SELECT 
                symbol, expiry, strike, option_type, ts, ltp, oi, volume,
                date_trunc('hour', ts) + INTERVAL '5 minute' * FLOOR(EXTRACT(minute FROM ts) / 5) as bucket_ts
            FROM {TEST_SCHEMA}.option_chain_ticks
            WHERE ts >= NOW() - make_interval(secs => {lookback_seconds})
        ),
        aggregated AS (
            SELECT 
                symbol, expiry, strike, option_type, bucket_ts,
                bucket_ts::date as trade_date,
                (array_agg(ltp ORDER BY ts))[1] as open,
                MAX(ltp) as high,
                MIN(ltp) as low,
                (array_agg(ltp ORDER BY ts DESC))[1] as close,
                (array_agg(oi ORDER BY ts))[1] as oi_open,
                MAX(oi) as oi_high,
                MIN(oi) as oi_low,
                (array_agg(oi ORDER BY ts DESC))[1] as oi_close,
                (array_agg(volume ORDER BY ts))[1] as vol_open,
                MAX(volume) as vol_high,
                MIN(volume) as vol_low,
                (array_agg(volume ORDER BY ts DESC))[1] as vol_close,
                COUNT(*) as tick_count
            FROM recent_ticks
            GROUP BY symbol, expiry, strike, option_type, bucket_ts
        )
        INSERT INTO {TEST_SCHEMA}.option_chain_candles_5m 
            (symbol, expiry, strike, option_type, bucket_ts, trade_date,
             open, high, low, close, 
             oi_open, oi_high, oi_low, oi_close,
             vol_open, vol_high, vol_low, vol_close, tick_count)
        SELECT * FROM aggregated
        ON CONFLICT (symbol, expiry, strike, option_type, bucket_ts) DO UPDATE SET
            high = GREATEST({TEST_SCHEMA}.option_chain_candles_5m.high, EXCLUDED.high),
            low = LEAST({TEST_SCHEMA}.option_chain_candles_5m.low, EXCLUDED.low),
            close = EXCLUDED.close,
            oi_high = GREATEST({TEST_SCHEMA}.option_chain_candles_5m.oi_high, EXCLUDED.oi_high),
            oi_low = LEAST({TEST_SCHEMA}.option_chain_candles_5m.oi_low, EXCLUDED.oi_low),
            oi_close = EXCLUDED.oi_close,
            vol_high = GREATEST({TEST_SCHEMA}.option_chain_candles_5m.vol_high, EXCLUDED.vol_high),
            vol_low = LEAST({TEST_SCHEMA}.option_chain_candles_5m.vol_low, EXCLUDED.vol_low),
            vol_close = EXCLUDED.vol_close,
            tick_count = {TEST_SCHEMA}.option_chain_candles_5m.tick_count + EXCLUDED.tick_count,
            updated_at = NOW()
        RETURNING symbol, strike, option_type
    """
    
    result = await conn.fetch(query)
    count = len(result)
    
    if count > 0:
        logger.info("aggregation_completed", candles_upserted=count)
    
    return count


async def get_candles(conn: asyncpg.Connection) -> List[Dict[str, Any]]:
    """Get all candles from test schema."""
    rows = await conn.fetch(f"""
        SELECT symbol, expiry, strike, option_type, bucket_ts, 
               open, high, low, close, 
               oi_open, oi_high, oi_low, oi_close,
               vol_open, vol_high, vol_low, vol_close, tick_count
        FROM {TEST_SCHEMA}.option_chain_candles_5m
        ORDER BY symbol, strike, option_type, bucket_ts
    """)
    return [dict(row) for row in rows]


async def test_basic_aggregation() -> bool:
    """
    Test 1: Basic aggregation - multiple ticks aggregate to single candle.
    
    Expected: 3 ticks for same strike/option_type ‚Üí 1 candle with correct OHLC
    """
    print("\n" + "="*60)
    print("TEST 1: Basic Aggregation")
    print("="*60)
    
    conn = await asyncpg.connect(**DB_CONFIG)
    try:
        await cleanup_test_data(conn)
        
        # Insert 3 ticks for NIFTY CE 23500 using offset_seconds
        ticks = [
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(), 
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 8, "ltp": Decimal("150.00"),  # OPEN
             "oi": 100000, "volume": 5000},
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 5, "ltp": Decimal("152.50"),  # HIGH
             "oi": 100500, "volume": 5100},
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 2, "ltp": Decimal("151.00"),  # CLOSE
             "oi": 101000, "volume": 5200},
        ]
        
        await insert_test_ticks(conn, ticks)
        
        # Run aggregation with 10 second lookback
        count = await aggregate_option_ticks_to_candles(conn, lookback_seconds=10)
        
        # Verify results
        candles = await get_candles(conn)
        
        print(f"\nInserted ticks: 3")
        print(f"Candles created: {count}")
        
        if len(candles) != 1:
            print(f"‚ùå FAIL: Expected 1 candle, got {len(candles)}")
            return False
        
        candle = candles[0]
        print(f"\nCandle details:")
        print(f"  Symbol: {candle['symbol']}")
        print(f"  Strike: {candle['strike']}")
        print(f"  Open: {candle['open']} (expected: 150.00)")
        print(f"  High: {candle['high']} (expected: 152.50)")
        print(f"  Low: {candle['low']} (expected: 150.00)")
        print(f"  Close: {candle['close']} (expected: 151.00)")
        print(f"  OI Close: {candle['oi_close']} (expected: 101000)")
        print(f"  Tick Count: {candle['tick_count']} (expected: 3)")
        
        # Validate
        checks = [
            (candle['open'] == Decimal("150.00"), "open"),
            (candle['high'] == Decimal("152.50"), "high"),
            (candle['low'] == Decimal("150.00"), "low"),
            (candle['close'] == Decimal("151.00"), "close"),
            (candle['oi_close'] == 101000, "oi_close"),
            (candle['tick_count'] == 3, "tick_count"),
        ]
        
        all_passed = True
        for passed, field in checks:
            if not passed:
                print(f"‚ùå FAIL: {field} mismatch")
                all_passed = False
        
        if all_passed:
            print("\n‚úÖ TEST 1 PASSED: Basic aggregation works correctly")
        
        return all_passed
        
    finally:
        await conn.close()


async def test_incremental_aggregation() -> bool:
    """
    Test 2: Incremental aggregation - new ticks update existing candle.
    
    Expected: First batch creates candle, second batch updates it with new high/close
    """
    print("\n" + "="*60)
    print("TEST 2: Incremental Aggregation")
    print("="*60)
    
    conn = await asyncpg.connect(**DB_CONFIG)
    try:
        await cleanup_test_data(conn)
        
        # First batch: 2 ticks
        ticks_batch1 = [
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 8, "ltp": Decimal("150.00"),
             "oi": 100000, "volume": 5000},
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 6, "ltp": Decimal("151.00"),
             "oi": 100500, "volume": 5100},
        ]
        
        await insert_test_ticks(conn, ticks_batch1)
        count1 = await aggregate_option_ticks_to_candles(conn, lookback_seconds=10)
        
        candles_after_batch1 = await get_candles(conn)
        
        if len(candles_after_batch1) == 0:
            print("‚ùå FAIL: No candles created after batch 1")
            return False
            
        print(f"\nAfter batch 1:")
        print(f"  Candles: {count1}")
        print(f"  High: {candles_after_batch1[0]['high']}")
        print(f"  Close: {candles_after_batch1[0]['close']}")
        print(f"  Tick count: {candles_after_batch1[0]['tick_count']}")
        
        # Second batch: 2 more ticks with new high
        ticks_batch2 = [
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 4, "ltp": Decimal("155.00"),  # NEW HIGH
             "oi": 101000, "volume": 5200},
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 2, "ltp": Decimal("153.00"),  # NEW CLOSE
             "oi": 101500, "volume": 5300},
        ]
        
        await insert_test_ticks(conn, ticks_batch2)
        count2 = await aggregate_option_ticks_to_candles(conn, lookback_seconds=10)
        
        candles_after_batch2 = await get_candles(conn)
        candle = candles_after_batch2[0]
        
        print(f"\nAfter batch 2:")
        print(f"  Candles updated: {count2}")
        print(f"  High: {candle['high']} (expected: 155.00 - GREATEST)")
        print(f"  Low: {candle['low']} (expected: 150.00 - LEAST)")
        print(f"  Close: {candle['close']} (expected: 153.00 - latest)")
        print(f"  Tick count: {candle['tick_count']} (expected: 6 - batch1(2) + batch2_aggregation(4))")
        
        # Validate
        # Note: tick_count = 6 because second aggregation sees all 4 ticks in window
        # and adds them to existing 2, giving 2 + 4 = 6
        checks = [
            (candle['high'] == Decimal("155.00"), "high should be GREATEST"),
            (candle['low'] == Decimal("150.00"), "low should be LEAST"),
            (candle['close'] == Decimal("153.00"), "close should be latest"),
            (candle['tick_count'] == 6, "tick_count should be 6 (2 + 4 from second run)"),
        ]
        
        all_passed = True
        for passed, msg in checks:
            if not passed:
                print(f"‚ùå FAIL: {msg}")
                all_passed = False
        
        if all_passed:
            print("\n‚úÖ TEST 2 PASSED: Incremental aggregation works correctly")
        
        return all_passed
        
    finally:
        await conn.close()


async def test_multiple_strikes() -> bool:
    """
    Test 3: Multiple strikes - each strike/option_type gets its own candle.
    
    Expected: 4 different strike/option_type combinations ‚Üí 4 candles
    """
    print("\n" + "="*60)
    print("TEST 3: Multiple Strikes")
    print("="*60)
    
    conn = await asyncpg.connect(**DB_CONFIG)
    try:
        await cleanup_test_data(conn)
        
        # Insert ticks for multiple strikes
        ticks = [
            # NIFTY CE 23500
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 5, "ltp": Decimal("150.00"),
             "oi": 100000, "volume": 5000},
            # NIFTY PE 23500
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "PE",
             "offset_seconds": 5, "ltp": Decimal("145.00"),
             "oi": 95000, "volume": 4500},
            # NIFTY CE 23600
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23600"), "option_type": "CE",
             "offset_seconds": 5, "ltp": Decimal("100.00"),
             "oi": 80000, "volume": 3000},
            # BANKNIFTY CE 50000
            {"symbol": "banknifty", "expiry": datetime(2026, 2, 12).date(),
             "strike": Decimal("50000"), "option_type": "CE",
             "offset_seconds": 5, "ltp": Decimal("200.00"),
             "oi": 50000, "volume": 2000},
        ]
        
        await insert_test_ticks(conn, ticks)
        count = await aggregate_option_ticks_to_candles(conn, lookback_seconds=10)
        
        candles = await get_candles(conn)
        
        print(f"\nInserted ticks: 4 (different strikes)")
        print(f"Candles created: {count}")
        print(f"\nCandles:")
        for c in candles:
            print(f"  {c['symbol']} {c['option_type']} {c['strike']}: close={c['close']}")
        
        if count != 4:
            print(f"‚ùå FAIL: Expected 4 candles, got {count}")
            return False
        
        print("\n‚úÖ TEST 3 PASSED: Multiple strikes create separate candles")
        return True
        
    finally:
        await conn.close()


async def test_lookback_window() -> bool:
    """
    Test 4: Lookback window - only ticks within window are aggregated.
    
    Expected: Old ticks (>10s) are not included in aggregation
    """
    print("\n" + "="*60)
    print("TEST 4: Lookback Window")
    print("="*60)
    
    conn = await asyncpg.connect(**DB_CONFIG)
    try:
        await cleanup_test_data(conn)
        
        # Insert old tick (outside 10s window)
        old_tick = [
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 30,  # 30 seconds ago
             "ltp": Decimal("140.00"),
             "oi": 90000, "volume": 4000},
        ]
        
        # Insert recent tick (within 10s window)
        recent_tick = [
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 5,  # 5 seconds ago
             "ltp": Decimal("150.00"),
             "oi": 100000, "volume": 5000},
        ]
        
        await insert_test_ticks(conn, old_tick)
        await insert_test_ticks(conn, recent_tick)
        
        # Aggregate with 10 second lookback
        count = await aggregate_option_ticks_to_candles(conn, lookback_seconds=10)
        
        candles = await get_candles(conn)
        
        print(f"\nInserted: 1 old tick (30s ago), 1 recent tick (5s ago)")
        print(f"Candles created: {count}")
        
        if len(candles) != 1:
            print(f"‚ùå FAIL: Expected 1 candle, got {len(candles)}")
            return False
        
        candle = candles[0]
        print(f"\nCandle close: {candle['close']} (expected: 150.00 from recent tick)")
        print(f"Tick count: {candle['tick_count']} (expected: 1)")
        
        if candle['close'] != Decimal("150.00") or candle['tick_count'] != 1:
            print("‚ùå FAIL: Old tick was incorrectly included")
            return False
        
        print("\n‚úÖ TEST 4 PASSED: Lookback window correctly filters old ticks")
        return True
        
    finally:
        await conn.close()


async def test_catchup_aggregation() -> bool:
    """
    Test 5: Catch-up aggregation - 1 hour lookback for startup.
    
    Expected: Ticks from 30 minutes ago are included with 1 hour lookback
    """
    print("\n" + "="*60)
    print("TEST 5: Catch-up Aggregation (1 hour lookback)")
    print("="*60)
    
    conn = await asyncpg.connect(**DB_CONFIG)
    try:
        await cleanup_test_data(conn)
        
        # Insert tick from 30 minutes ago
        old_tick = [
            {"symbol": "nifty", "expiry": datetime(2026, 2, 13).date(),
             "strike": Decimal("23500"), "option_type": "CE",
             "offset_seconds": 1800,  # 30 minutes ago
             "ltp": Decimal("145.00"),
             "oi": 95000, "volume": 4500},
        ]
        
        await insert_test_ticks(conn, old_tick)
        
        # Aggregate with 1 hour lookback (catch-up)
        count = await aggregate_option_ticks_to_candles(conn, lookback_seconds=3600)
        
        candles = await get_candles(conn)
        
        print(f"\nInserted: 1 tick from 30 minutes ago")
        print(f"Candles created with 1h lookback: {count}")
        
        if count != 1:
            print(f"‚ùå FAIL: Expected 1 candle, got {count}")
            return False
        
        print("\n‚úÖ TEST 5 PASSED: Catch-up aggregation includes older ticks")
        return True
        
    finally:
        await conn.close()


async def main():
    """Run all tests."""
    print("\n" + "="*60)
    print("FIX-064 Phase 3: Option Tick Aggregation Tests")
    print("="*60)
    print(f"Test Schema: {TEST_SCHEMA}")
    print(f"Database: {DB_CONFIG['host']}")
    
    # Setup
    conn = await asyncpg.connect(**DB_CONFIG)
    await setup_test_schema(conn)
    await conn.close()
    
    # Run tests
    results = []
    
    results.append(("Basic Aggregation", await test_basic_aggregation()))
    results.append(("Incremental Aggregation", await test_incremental_aggregation()))
    results.append(("Multiple Strikes", await test_multiple_strikes()))
    results.append(("Lookback Window", await test_lookback_window()))
    results.append(("Catch-up Aggregation", await test_catchup_aggregation()))
    
    # Summary
    print("\n" + "="*60)
    print("TEST SUMMARY")
    print("="*60)
    
    passed = 0
    failed = 0
    for name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status}: {name}")
        if result:
            passed += 1
        else:
            failed += 1
    
    print(f"\nTotal: {passed} passed, {failed} failed")
    
    if failed == 0:
        print("\nüéâ ALL TESTS PASSED - Python aggregation is ready for production!")
    else:
        print("\n‚ö†Ô∏è  Some tests failed - review before deploying")
    
    return failed == 0


if __name__ == "__main__":
    asyncio.run(main())
